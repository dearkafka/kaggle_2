{
    "contents" : "\n# explicitly mention data.table usage at the beginning \n\n#load packages\n\nrequire(xgboost); require(readr); require(caret); require(doParallel); require(data.table); require(FeatureHashing); require(sqldf); require(dplyr)\n\nset.seed(11102015)\n\n################################################################################################################\n\n#read in data \n\n#train_raw <- read_csv(\"C:/Users/amulya/Documents/Kaggle/Walmart/train.csv\")\n\n#test_raw <- read_csv(\"C:/Users/amulya/Documents/Kaggle/Walmart/test.csv\")\n\ntrain_raw <- read_csv(\"D:/kaggle/walmart_seg/Data/train.csv\")\n\ntest_raw <- read_csv(\"D:/kaggle/walmart_seg/Data/test.csv\")\n\nvisit_num <- test_raw$VisitNumber\n\n################################################################################################################\n\nfeature.names <- names(train_raw)[!names(train_raw) %in% c(\"TripType\")]\n\nresponse <- names(train_raw)[1]\n\nresponse <- train_raw[ , response] \n\nclass_old <- sort(unique(response$TripType))\n\nclass_new <- seq(0, 37)\n\n#replace elements of class_old with elements of class_new in response\n\nfor( i in 1:38 ){\n  \n  train_raw$TripType[train_raw$TripType == class_old[i]] <- class_new[i]\n  \n}\n\ntable(train_raw$TripType)\n\n################################################################################################################\n\n\n#very basic stuff----------------------------------------------------------------------------------------------\n\n# options : 1. find better ways of extracting info from text variables\n\n#           2. one way is stuff such as count, tf idf etc...\n\n#           3. there are other wayss which as of 11072015 I dnt know but I will refer @Kaggle\n\n#           4. Below mentioned is a very basic way of using character information.\n\n\ncat(\"assuming text variables are categorical & replacing them with numeric ids\\n\")\n\nfor (f in feature.names) {\n  \n  if (class(train_raw[[f]]) == \"character\") {\n    \n    levels <- unique(c(train_raw[[f]], test_raw[[f]]))\n    \n    train_raw[[f]] <- as.integer(factor(train_raw[[f]], levels=levels))\n    \n    test_raw[[f]]  <- as.integer(factor(test_raw[[f]],  levels=levels))\n  }\n}\n\n\n###############################################################################################################\n\n# combine train and test\n\n# easier way to manipulate data for both train and test\n\n# columns in both test and train should be the same for training , testing , validation and prediction\n\n\n\ntmp <- rbind(train_raw[ , feature.names], test_raw)\n\n# IMP : FACED ISSUES [ READ : CODE BREAKS] WHEN tbl_df WAS PRESENT CLASS\n\n#     : as.factor CONVERSION COULDN`T GO THROUGH \n\n#     : REMOVING THE CLASS PROVED BENEFICIAL ; RUN THE BELOW CODE FOR CONVERSION\n\ntmp <- data.frame(tmp)\n\n\n# for counts (1 - way, 2 - way, 3 - way)\n\n# selected columns should contain factors\n\n# so first select columns and then convert them into factors  \n\n# Also maintain name used in below code for easy reproducibilty ( use the same names for ur present df)\n\n\n\ntmp_factors = tmp[ , feature.names]; dim(tmp_factors)\n\nlen = length(names(tmp_factors))\n\nfor (i in 1:len) {\n  \n  print(paste0( i / (len) *100, \"%\"))\n  \n  tmp_factors[ , i] <- as.factor(tmp_factors[ , i])\n  \n}\n\n#Important step ^^^^\n\n#############################################################################################################\n\n\n# 2 way count\n\nnms <- combn(names(tmp_factors), 2)\n\ndim(nms)\n\nnms_df <- data.frame(nms) \n\nlen = length(names(nms_df))\n\nfor (i in 1:len) {\n  \n  nms_df[, i] <- as.character(nms_df[, i])\n  \n}\n\ntmp_count <- data.frame(id = 1:dim(tmp)[1])\n\nfor(i in 1:dim(nms_df)[2]){\n  \n  \n  #new df \n  \n  print(((i / dim(nms_df)[2]) * 100 ))\n  \n  tmp_count[, paste(i, \"_two\", sep=\"\")] <- my.f2cnt(th2 = tmp, \n                                                    \n                                                    vn1 = nms_df[1,i], \n                                                    \n                                                    vn2 = nms_df[2,i] )\n  \n}\n\n###############################################################################################################\n\n\n\n#3 way count\n\nnms <- combn(names(tmp_factors), 3)\n\ndim(nms)\n\nnms_df <- data.frame(nms);\n\nlen = length(names(nms_df))\n\nfor (i in 1:len) {\n  \n  print(paste0(( i / len) *100, \"%\"))\n  \n  nms_df[, i] <- as.character(nms_df[, i])\n  \n}\n\nfor(i in 1:dim(nms_df)[2]){\n  \n  #new df \n  \n  print((i / dim(nms_df)[2]) * 100)\n  \n  tmp_count[, paste(i, \"_three\", sep=\"\")] <- my.f3cnt(th2 = tmp, \n                                                      \n                                                      vn1 = nms_df[1,i], \n                                                      \n                                                      vn2 = nms_df[2,i], \n                                                      \n                                                      vn3 = nms_df[3,i])\n  \n}\n\n\n##############################################################################################################\n\n\n\n#one way count\n\nlen = dim(tmp_factors)[2]\n\nfor(i in 1:len){\n  \n  \n  print((i / len) * 100 )\n  \n  tmp_factors$x <- tmp_factors[, i]\n  \n  sum1 <- sqldf(\"select x, count(1) as cnt\n                \n                from tmp_factors  group by 1 \")\n  \n  tmp1 <- sqldf(\"select cnt from tmp_factors a left join sum1 b on a.x=b.x\")\n  \n  tmp_count[, paste(names(tmp_factors)[i], \"_one\", sep=\"\")] <- tmp1$cnt\n  \n}  \n\n###############################################################################################################\n\n\n# IMP : This step is not required unless the method of creating tmp_factors is similar to \n\n# that used in springleaf Marketing response challenge\n\n# for this contest skipping this step as it is not required\n\n\n\n#need to convert all of tmp_factors to numeric\n\n\nlen = length(names(tmp_factors))\n\nfor (i in 1:len) {\n  \n  tmp_factors[, i] <- as.numeric(tmp_factors[, i])\n  \n}\n\n\n\n###############################################################################################################\n\n\n\n#use this code before running dummy variables conversion \n\n#Note IMP:  1. Selected columns should be of factors\n\n\n#dummify few columns\n\n\nname <- c(\"Weekday\", \"DepartmentDescription\", \"ScanCount\")\n\ntmp_dummy <- (tmp[ , name ])\n\nlen = length(names(tmp_dummy))\n\nfor (i in 1:len) {\n  \n  print(paste0(( i / len) * 100, \"%\"))\n  \n  levels <- unique(tmp_dummy[[i]])\n  \n  tmp_dummy[, i] <- as.factor(tmp_dummy[, i])\n  \n}\n\n\n\ndummies <- dummyVars( ~ ., data = tmp_dummy)\n\ngc()\n\ntmp_dummy <- predict(dummies, newdata = tmp_dummy)\n\ntmp_dummy <- data.frame(tmp_dummy)\n\ndim(tmp_dummy)\n\n##############################################################################################################\n\n\n#test if the below code works before running \n\n\ntmp_features <- data.frame(id = 1:dim(tmp)[1])\n\n\n\n# features for difference from mean\n\nfor(i in 1:ncol(tmp_new)){\n  \n  tmp_features[, paste(names(tmp_new)[i], \"_mean\", sep=\"\")] <- tmp_new[, i] - mean(tmp_new[, i])\n  \n  \n}\n\n\n\n\n# features for standardization\n\nfor(i in 1:ncol(tmp_new)){\n  \n  tmp_features[, paste0(names(tmp_new)[i], \"_zscore\")] <- ((tmp_new[, i] - mean(tmp_new[, i])) / sd(tmp_new[, i]))\n  \n  \n}\n\n###########################################################################################################\n\n\n# Take interaction features from feature importance from various different algos (Eg : 20 from each)\n\n# Interaction features\n\n\nint_col <- c()\n\ntmp_int <- tmp_new[ , int_col]\n\n\n\n# create + interaction features\n\n\nfor (i in 1:ncol(tmp_int)) {\n  \n  for (j in (i + 1) : (ncol(tmp_int) + 1)) {\n    \n    var.x <- colnames(tmp_int)[i]\n    \n    var.y <- colnames(tmp_int)[j]\n    \n    var.new <- paste0(var.x, '_plus_', var.y)\n    \n    tmp_int[, paste0(var.new)] <- tmp_int[, i] + tmp_int[, j]\n    \n  }\n}\n\n\n\n\n# create - interaction features\n\n\nfor (i in 1:ncol(tmp_int)) {\n  \n  for (j in (i + 1) : (ncol(tmp_int) + 1)) {\n    \n    var.x <- colnames(tmp_int)[i]\n    \n    var.y <- colnames(tmp_int)[j]\n    \n    var.new <- paste0(var.x, '_minus_', var.y)\n    \n    tmp_int[, paste0(var.new)] <- tmp_int[, i] - tmp_int[, j]\n    \n  }\n}\n\n\n\n\n\n# create * interaction features\n\n\nfor (i in 1:ncol(tmp_int)) {\n  \n  for (j in (i + 1) : (ncol(tmp_int) + 1)) {\n    \n    var.x <- colnames(tmp_int)[i]\n    \n    var.y <- colnames(tmp_int)[j]\n    \n    var.new <- paste0(var.x, '_mult_', var.y)\n    \n    tmp_int[, paste0(var.new)] <- tmp_int[, i] * tmp_int[, j]\n    \n  }\n}\n\n\n\n\n\n# create / interaction features\n\n\nfor (i in 1:ncol(tmp_int)) {\n  \n  for (j in (i + 1) : (ncol(tmp_int) + 1)) {\n    \n    var.x <- colnames(tmp_int)[i]\n    \n    var.y <- colnames(tmp_int)[j]\n    \n    var.new <- paste0(var.x, '_divide_', var.y)\n    \n    tmp_int[, paste0(var.new)] <- tmp_int[, i] / tmp_int[, j]\n    \n  }\n}\n\n\n\ntmp_int <- tmp_int[, -int_col]\n\n################################################################################################\n\n\n# Dealing with text data\n\n# Tried methods : 1. Length of string (nchar)\n\n#               : 2. number of words\n\n#               : 3. N-Grams\n\n\n# create a data frame with columns being of strings (character type)\n\n# create a new tmp df with raw features\n\n# these changes introduced NA`s in dval N dtrain \n\n# solution : remove NA`s before combining \n\ntmp_1 <- read_csv(\"D:/kaggle/walmart_seg/Data/train.csv\")[-1]\n\ntmp_2 <- read_csv(\"D:/kaggle/walmart_seg/Data/test.csv\")\n\ntmp <- rbind(tmp_1, tmp_2)\n\ntmp_str <- data.frame((tmp[ , \"DepartmentDescription\"]))\n\n\ntmp_str[is.na(tmp_str)] <- 0\n\n\nnames(tmp_str) = (\"Dept_Desc\")\n\n\n\n\n#convert columns from character to factors in a data frame\n\n# code sourced from Stack Overflow\n\n\ni <- sapply(tmp_str, is.factor)\n\n\ntmp_str[i] <- lapply(tmp_str[i], as.character)\n\n\ntmp_str[, paste0(\"str_len\")] <-  nchar(x = tmp_str$Dept_Desc) \n\n\n\n# calculate number of words\n\n\ntmp_str$Dept_Desc <- gsub(' {2,}',' ', tmp_str$Dept_Desc)\n\nlnth <- rep(0, nrow(tmp_str))\n\nfor(i in 1:nrow(tmp_str)) {\n  \n  lnth[i] <-  length(strsplit(tmp_str$Dept_Desc[i],' ')[[1]])\n  \n}\n\ntmp_str$num_wrd <- lnth\n\n\n\n# calculate N-Grams of words\n\n\nrm(tmp); rm(tmp_1); rm(tmp_2)\n\n############################################################################################################\n\n\n# combine all temporarily created df`s into tmp_new in a single piece of code  \n\n# tmp_count\n\n# tmp_dummy\n\n# tmp_features\n\n# tmp_int\n\n# tmp_str\n\n\n#tmp_new = cbind.data.frame(tmp_new, tmp_dummy)\n\n\ntmp_new = cbind.data.frame(tmp, tmp_count, tmp_dummy)\n\ntmp_new = cbind.data.frame(tmp_new, tmp_features)\n\ntmp_new = cbind.data.frame(tmp_new, tmp_str)\n\n\ngc()\n\n#remove unwanted df\n\nrm(nms); rm(nms_df); rm(sum1); rm(tmp_count); rm(tmp_factors); rm(tmp1); rm(tmp_features) \n\nrm(tmp); rm(tmp_str); rm(train); rm(test)\n\n#rm(tmp_new_cpy); rm(tmp_cpy)\n\ngc()\n\n#seperate train from test\n\ntrain <- tmp_new[c(1:647054),]\n\ntest <- tmp_new[c(647055:1300700),]\n\ndim(train); dim(test)\n\ngc()\n\n#rm(tmp_new); rm(tmp_str)\n\n#gc()\n\n##############################################################################################################\n\n#check for new ways to impute NA\n\n# options : 1. PLot the distributions of each column\n\n#           2. Plot the distribution of NA\n\n#           3. Impute by mean, KNN ( both are found in caret ) **** should try for this competition *** \n\n\ntrain[is.na(train)] <- 0\n\ngc()\n\ntest[is.na(test)] <- 0\n\ngc()\n\n\n#############################################################################################################################\n\n# Impute method : KnnImpute\n\n# columns upc and fineline number has 419 NA's \n\npp_1_test = preProcess(iris_miss_1, method = \"knnImpute\")\n\nset.seed(1)\n\ntest_1_result <- predict(pp_1_test, iris_miss_1)\n\n#bag Impute\n\npreProc <- preProcess(method=\"bagImpute\", training[, 1:4])\n\ntraining[, 1:4] <- predict(preProc, training[, 1:4])\n",
    "created" : 1446838548643.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1108365047",
    "id" : "F8EEA5E8",
    "lastKnownWriteTime" : 1447425056,
    "path" : "D:/kaggle/walmart_seg/PRE-PROCESS.R",
    "project_path" : "PRE-PROCESS.R",
    "properties" : {
        "tempName" : "Untitled2"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "type" : "r_source"
}