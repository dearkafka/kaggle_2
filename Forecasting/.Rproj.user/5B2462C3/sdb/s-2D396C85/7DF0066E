{
    "contents" : "library(caret)\n\nlibrary(readr)\n\nlibrary(xgboost)\n\ntrain <- read_csv(\"D:/kaggle/Springleaf/DATA/CSV/train.csv\")\n\ntest <- read_csv(\"D:/kaggle/Springleaf/DATA/CSV/test.csv\")\n\nfeature.names <- names(train)[2:(ncol(train)-1)]\n\n\nfor (f in feature.names) {\n  \n  if (class(train[[f]])==\"character\") {\n    \n    levels <- unique(c(train[[f]], test[[f]]))\n    \n    train[[f]] <- as.integer(factor(train[[f]], levels=levels))\n    \n    test[[f]]  <- as.integer(factor(test[[f]],  levels=levels))\n    \n  }\n}\n\ntrain[is.na(train)] <- -1\n\ntest[is.na(test)]   <- -1\n\nfeature_1 <- benchmark$target[1:145231] \n\ntrain$feature1 <- feature_1\n\ntest$feature1 <- benchmark$target\n\nsplit <- createDataPartition(train$target, p = .75, list = FALSE)\n\nresponse <- train$target\n\ntrain$target <- NULL\n\nfeature.names <- names(train)[2:(ncol(train))]\n\ntraining <- train[ split,]\n\ntesting  <- train[-split,]\n\nresponse_testing <-  response[-split]\n\nresponse_training <- response[split]\n\ndtrain <- xgb.DMatrix(data.matrix(training[,feature.names]), label= response_training)\n\ndval <- xgb.DMatrix(data.matrix(testing[,feature.names]), label= response_testing)\n\nwatchlist <- list(train = dtrain, test = dval)\n\nparam <- list(  objective   = \"binary:logistic\", \n\n                eta                 = 0.014,\n                \n                max_depth           = 10,\n                \n                subsample           = 0.7,\n                \n                colsample_bytree    = 0.7,\n                \n                eval_metric         = \"auc\"\n)\n\n\nxgb.cv(params = param, dtrain)\n\n\n\nclf_first <- xgb.train( params = param, \n                        \n                        data                = dtrain, \n                        \n                        nrounds             = 520, # changed from 300\n                        \n                        verbose             = 2, \n                        \n                        watchlist = watchlist,\n                        \n                        nthread = 2,\n                        \n                        maximize = TRUE)\n\nsubmission_second <- data.frame(ID=test$ID)\n\nsubmission_second$target <- NA \n\nsubmission_second[,\"target\"] <- predict(clf_first, data.matrix(test[,feature.names]))\n\nwrite_csv(submission_second, \"second.csv\")\n\nxgb.dump(model = clf_first, \"second.txt\", with.stats = T)\n\nxgb.save(clf_first, \"xgb_second.R\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrain <- train[sample(nrow(train), 80000),]\n\nh <- sample(nrow(train), 40000)\ntrain <-train[h,]\ngc()\n\ncat(\"Making train and validation matrices\\n\")\n\ndtrain <- xgb.DMatrix(data.matrix(train[,feature.names]), label=train$target)\n\nval<-train[-h,]\ngc()\n\ndval <- xgb.DMatrix(data.matrix(val[,feature.names]), label=val$target)\n\nwatchlist <- watchlist <- list(eval = dval, train = dtrain)\n\nparam <- list(  objective           = \"binary:logistic\", \n                # booster = \"gblinear\",\n                eta                 = 0.001,\n                max_depth           = 13,  # changed from default of 6\n                subsample           = 0.6,\n                colsample_bytree    = 0.75,\n                eval_metric         = \"auc\"\n                # alpha = 0.0001, \n                # lambda = 1\n)\n\nclf <- xgb.train(   params              = param, \n                    data                = dtrain, \n                    nrounds             = 50, # changed from 300\n                    verbose             = 2, \n                    early.stop.round    = 10,\n                    watchlist           = watchlist,\n                    maximize            = TRUE)\n\ncat(\"making predictions in batches due to 8GB memory limitation\\n\")\n\nsubmission <- data.frame(ID=test$ID)\nsubmission$target <- NA \nfor (rows in split(1:nrow(test), ceiling((1:nrow(test))/10000))) {\n  submission[rows, \"target\"] <- predict(clf, data.matrix(test[rows,feature.names]))\n  \n  # submission2 <- data.frame(ID=test$ID)\n  # submission2$target2 <- NA \n  # for (rows in split(1:nrow(test), ceiling((1:nrow(test))/10000))) {\n  #     submission2[rows, \"target2\"] <- predict(clf, data.matrix(test[rows,feature.names]))\n  \n}\n\n\n# submission <- merge(submission, submission2, by = \"ID\", all.x = TRUE)\n# submission$target <- submission$target1*0.4 + submission$target2*0.6\n# submission <- submission[,c(1,4)]\n\ncat(\"saving the submission file\\n\")\nwrite_csv(submission, \"xgb_b6.csv\")",
    "created" : 1445745948569.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "185578328",
    "id" : "7DF0066E",
    "lastKnownWriteTime" : 1441085778,
    "path" : "D:/kaggle/Springleaf/working_file.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "type" : "r_source"
}