{
    "contents" : "\n# create folds------------------------------------------------------------------------------------------\n\ndataset_blend_train = matrix(0, nrow(train), 5)\n\ndataset_blend_test_j = matrix(0, nrow(test), 5) # this should always be number of folds\n\ndataset_blend_test = matrix(0, nrow(test), 5)\n\nresponse <- train.y\n\n# start iteration loop---------------------------------------------------------------------------------\n\nfor(j in 1:5)\n\n{  \n#  j = 1\n  \n  print(paste(\"starting glm iteration ; number :\", j))\n  \n  set.seed(2*05*2016*j)\n  \n  sample_train <- sample(x = nrow(train), size = nrow(train), replace = T )\n  \n  sample_test <- sample(x = nrow(test), size = nrow(test), replace = T )\n  \n  train <- train[sample_train, ]\n  \n  test <- train[sample_test, ]\n  \n  require(caret)\n  \n  skf = createFolds(response, k = 5)\n  \n  print(paste(nrow(dataset_blend_test_j),ncol(dataset_blend_test_j)))\n  \n  # start fold loop------------------------------------------------------------------------------------\n  \n  ### Loop over the folds\n  \n  i <- 0\n  \n  for (sk in skf) {\n    \n    i <- i + 1\n    \n    print(paste(\"Fold\", i))\n    \n    ### Extract and fit the train/test section for each fold\n        \n    tmp_train <- unlist(skf[i])\n    \n    x_train = train[-tmp_train,]\n    \n    y_train = response[-tmp_train]\n    \n    x_test  = train[tmp_train,]\n    \n    y_test  = response[tmp_train]\n    \n    require(h2o)\n    \n    localH2O <- h2o.init(nthreads = 4, max_mem_size = '12g')\n    \n    x_train$target <- (y_train)\n    \n    train.hex <- as.h2o(localH2O, object = x_train)\n    \n    test.hex <- as.h2o(localH2O, object = x_test)\n    \n    \n    myX <- names(train)\n    \n    myY <- \"target\"\n    \n    print(paste(\"training glm iteration :\", j, \"for Fold ; number :\", i))\n    \n    test_glm <- h2o.glm( x = myX,\n                    \n                    y = myY,\n                    \n                    training_frame = train.hex,\n                    \n                    family = \"binomial\",\n                    \n                    solver = \"L_BFGS\",\n                    \n                    link = \"logit\", \n                    \n                    standardize = T, \n                    \n                    lambda_search = T\n                    \n                    )\n\n    pred_glm <- h2o.predict(test_glm, newdata = test.hex)\n    \n    pred_glm <- as.data.frame(pred_glm)\n    \n    \n#     test_glm <- glm(formula = target ~ ., family = binomial(link = \"logit\"), data = x_train)\n        \n    \n    \n    dataset_blend_train[tmp_train, j] <- pred_glm$p1\n    \n    \n    print(paste(\"predicting glm for test set iteration :\", j, \"; Fold :\", i))\n    \n    test.hex <- as.h2o(localH2O, object = test)\n    \n    pred_glm <- h2o.predict(object = test_glm, newdata = test.hex)\n    \n    pred_glm <- as.data.frame(pred_glm)\n    \n    dataset_blend_test_j[, i] <- pred_glm$p1\n    \n  }\n  \n  dataset_blend_test[, j] <- rowMeans(dataset_blend_test_j)\n  \n}\n\nrequire(readr)\n\nwrite_csv(data.frame(dataset_blend_train), \"D:\\\\kaggle\\\\SANTANDER\\\\copy\\\\ENSM\\\\GLM\\\\TRAIN\\\\blend_train_glm_04232016_sample_1.csv\")\n\nwrite_csv(data.frame(dataset_blend_test), \"D:\\\\kaggle\\\\SANTANDER\\\\copy\\\\ENSM\\\\GLM\\\\TEST\\\\blend_test_glm_04232016_1_sample_1.csv\")\n\n########################################################################################################################",
    "created" : 1461426975942.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1210455414",
    "id" : "9E1E33D3",
    "lastKnownWriteTime" : 1461433438,
    "path" : "D:/kaggle/HOMESITE/blend/bag_glm.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 8,
    "source_on_save" : false,
    "type" : "r_source"
}