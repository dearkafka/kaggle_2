{
    "contents" : "\nx <-  c(\"start  of the first step\", \"Reading in the data\"); cat(x, sep = \"\\n\")\n\nlibrary(readr); library(xgboost); library(caret); library(lubridate)\n\nlibrary(doParallel); library(caret); library(sqldf)\n\nset.seed(867530099)\n\ntrain <- read_csv(\"D:/kaggle/Springleaf/DATA/CSV/train.csv\")\n\n# save ID and response\n\ntrain_target <- train$target\n\ntrain$target <- NULL\n\ntrain_ID <- train$ID\n\ntrain$ID <- NULL\n\ntest <- read_csv(\"D:/kaggle/Springleaf/DATA/CSV/test.csv\")\n\n# save ID and response\n\ntest_ID <- test$ID\n\ntest$ID <- NULL\n\n\nprint(dim(train)); print(dim(test))\n\n\n#bind train and test for better and easier pre-processing\n\ntmp <- rbind(train, test)\n\n#seperate out date columns in train and test (mostly by using a grep function)\n\ndatecolumns = c(\"VAR_0073\", \"VAR_0075\", \"VAR_0156\", \"VAR_0157\", \"VAR_0158\",\n  \n  \"VAR_0159\", \"VAR_0166\", \"VAR_0167\", \"VAR_0169\",\"VAR_0168\",\n  \n  \"VAR_0176\", \"VAR_0177\", \"VAR_0178\", \"VAR_0179\", \"VAR_0204\", \"VAR_0217\")\n\ntmp_date <- tmp[datecolumns]\n\n#convert into\n\ntmp_date <- data.frame(apply(tmp_date, 2,function(x)(\n                                 \n                      strptime(x, format = \"%d%b%y: %H:%M:%S\",tz = \"UTC\"))))\n\n\n\ntmp_date[,c(17:32)] <- data.frame(apply(tmp_date[, c(1:16)], 2, function(x) wday(x)))\n\nnames(tmp_date)[(17:32)] <- paste0(\"wday_\", names(tmp_date)[(1:16)])\n\n\n\ntmp_date[,c(33:48)] <- data.frame(apply(tmp_date[, c(1:16)], 2, function(x) mday(x)))\n\nnames(tmp_date)[(33:48)] <- paste0(\"mday_\", names(tmp_date)[(1:16)])\n\n\n\ntmp_date[, c(49:50)] <- data.frame(apply(tmp_date[, c(15:16)], 2, function(x) hour(x)))\n\nnames(tmp_date)[(49:50)] <- paste0(\"hour_\", names(tmp_date)[c(15:16)])\n\n\n\ntmp_date[, c(51:52)] <- data.frame(apply(tmp_date[, c(49:50)], 2, function(x)\n    \n                                   ifelse(x <= 6, 1,\n                              \n                                   ifelse(x <= 12, 2,\n                               \n                                   ifelse(x <= 18, 3,\n                                          \n                                   ifelse(x <= 24, 4))))))\n\n\nnames(tmp_date)[(51:52)] <- paste0(\"Dzones_\", names(tmp_date)[(15:16)])\n\n#plot histogram of dates\n\npar(mar = c(2,2,2,2),mfrow = c(4,4))\n\nfor (i in 1:16) {\n  \n  hist( tmp_date[,i], \"weeks\" ,format = \"%d %b %y\", main = names(tmp_date[,i]),\n    \n        xlab = \"\", ylab = \"\")\n  }\n\nfor (i in 1:16) {\n  \n  tmp_date[, i] <- as.numeric(tmp_date[, i])\n\n  }\n\n\ntmp_pre <-  preProcess(tmp_date, method = (\"BoxCox\"))\n\ntmp_pre_pred <- predict(tmp_pre, tmp_date)\n\ntmp_date <- tmp_pre_pred\n\n\n\n\ndim(tmp)\n\ntmp <- tmp[,!(names(tmp) %in% (datecolumns))]\n\ntmp <- cbind(tmp, tmp_date)\n\ndim(tmp); dim(tmp_date)\n\ngc()\n\nnzv <- read_csv(\"nzv.csv\")\n\ntmp <- tmp[,-nzv$nzv]\n\n##########################################################################################\n#using owen`s Amazon code approach\n\nmy.f2cnt <- function(th2, vn1, vn2, filter=TRUE) {\n  \n  df <- data.frame(f1=th2[,vn1], f2=th2[,vn2], filter=filter)\n  \n  sum1 <- sqldf(\"select f1, f2, count(*) as cnt \n                \n                from df \n                \n                where filter=1 \n                \n                group by 1,2\")\n  \n  tmp <- sqldf(\"select b.cnt \n               \n               from df a left join sum1 b \n               \n               on a.f1=b.f1 and a.f2=b.f2\")\n  \n  tmp$cnt[is.na(tmp$cnt)] <- 0\n  \n  return(tmp$cnt)\n\n  }\n\n#3 way count\n\nmy.f3cnt<-function(th2, vn1, vn2, vn3, filter=TRUE) {\n  \n  df<-data.frame(f1=th2[,vn1], f2=th2[,vn2], f3=th2[, vn3], filter=filter)\n  \n  sum1<-sqldf(\"select f1, f2, f3, count(*) as cnt \n              \n              from df \n              \n              where filter=1 \n              \n              group by 1,2, 3\")\n  \n  tmp<-sqldf(\"select b.cnt \n             \n             from df a left join sum1 b \n             \n             on a.f1=b.f1 and a.f2=b.f2 and a.f3=b.f3\")\n  \n  tmp$cnt[is.na(tmp$cnt)]<-0\n  \n  return(tmp$cnt)\n\n}\n\n\n# group data => create combinations of a given order\n\ngroupData <- function(xmat, degree)\n\n  {\n  \n  # indices of combinations\n  \n  xind <- combn(1:ncol(xmat), degree)\n  \n  # storage structure for the result\n  \n  agx <- foreach(ii = 1:ncol(xind), .combine = cbind ) %do%\n  \n    {\n    x <- xmat[,xind[1,ii]]\n    \n    for (jj in 2:nrow(xind))\n    \n      {\n      \n      x <- paste(x, xmat[,xind[jj,ii]], sep = \"_\")\n    \n      }\n    \n    x\n  }\n  \n  colnames(agx) <- paste(paste(\"f\", degree, sep = \"\"), 1:ncol(agx), sep = \"_\")\n  \n  return(agx)\n\n  }\n\n######################################################################################\n\nlen = length(names(tmp))\n  \n  names = rep(0, len)\n  \n  \n  for (i in 1:len) {\n    \n    print(paste0(( i / len) *100, \"%\"))\n    \n    if (length(table(tmp[[i]])) < 100) {\n      \n      names[i] = names(tmp)[i]\n      \n    }\n    \n  }\n  \n  names = names[names != 0]\n  \n  length(names)\n  \n  #names <- c(names, \"VAR_0200\", \"VAR_0241\",\"VAR_0404\", \"VAR_0493\")\n\n  tmp_factors = tmp[,(names(tmp) %in% names)]; dim(tmp_factors)\n  \n  len = length(names(tmp_factors))\n  \n  for (i in 1:len) {\n    \n    print(paste0(( i / len) *100, \"%\"))\n    \n    tmp_factors[, i] <- as.factor(tmp_factors[, i])\n    \n  }\n  \n##########################################################################################\n  \nimp_feature <- read_csv(\"D:/kaggle/Springleaf/xgb_featureImp.csv\")\n  \nimp_names <- (imp_feature$Feature)\n  \nimp_names <- sapply(imp_names, function(x) names(tmp)[x])\n  \nimp_names <- imp_names[1:200]\n\ntmp_factors <- tmp_factors[, (names(tmp_factors) %in% imp_names)]\n\n####################################################################################\n\n#2 way count\n\nnms <- combn(names(tmp_factors), 2)\n\ndim(nms)\n\nnms_df <- data.frame(nms) \n\nlen = length(names(nms_df))\n\nfor (i in 1:len) {\n  \n  nms_df[, i] <- as.character(nms_df[, i])\n  \n}\n\ntmp_count <- data.frame(id = 1:dim(tmp)[1])\n\nfor(i in 1:dim(nms_df)[2]){\n  \n\n    #new df \n \n  print(((i / dim(nms_df)[2]) * 100 ))\n  \n  tmp_count[, paste(i, \"_two\", sep=\"\")] <- my.f2cnt(th2 = tmp, \n                                                    \n                                                    vn1 = nms_df[1,i], \n                                                    \n                                                    vn2 = nms_df[2,i] )\n\n}\n\n\n#3 way count\n\nnms <- combn(names(tmp_factors), 3)\n\ndim(nms)\n\nnms_df <- data.frame(nms); nms_df <- nms_df[ c(1:3), c(1:200)]\n\n\nlen = length(names(nms_df))\n\nfor (i in 1:len) {\n  \n  print(paste0(( i / len) *100, \"%\"))\n  \n  nms_df[, i] <- as.character(nms_df[, i])\n  \n}\n\nfor(i in 1:dim(nms_df)[2]){\n  \n#new df \n  \n  print((i / dim(nms_df)[2]) * 100)\n\n  tmp_count[, paste(i, \"_three\", sep=\"\")] <- my.f3cnt(th2 = tmp, \n                                                    \n                                                    vn1 = nms_df[1,i], \n                                                    \n                                                    vn2 = nms_df[2,i], \n                                                    \n                                                    vn3 = nms_df[3,i])\n  \n  }\n\n\n#one way count\n\nlen = dim(tmp_factors)[2]\n\nfor(i in 1:len){\n  \n  \n    print((i / len) * 100 )\n    \n    tmp_factors$x <- tmp_factors[, i]\n    \n    sum1 <- sqldf(\"select x, count(1) as cnt\n       \n                from tmp_factors  group by 1 \")\n\n    tmp1 <- sqldf(\"select cnt from tmp_factors a left join sum1 b on a.x=b.x\")\n\n    tmp_count[, paste(names(tmp_factors)[i], \"_cnt\", sep=\"\")] <- tmp1$cnt\n  \n    }  \n\n#need to convert all of tmp_factors to numeric\n\nlen = length(names(tmp_factors))\n\nfor (i in 1:len) {\n  \n  tmp_factors[, i] <- as.numeric(tmp_factors[, i])\n  \n}\n\n#############################################################################\n\ntmp_new = cbind.data.frame(tmp, tmp_factors, tmp_count)\n\n#leave one out average left out\n\n################################################################################                \n#need to rm , #large memory footprint\n\ndummies <- dummyVars( ~ ., data = tmp_factors)\n                \ntmp_factors <- predict(dummies, newdata = tmp_factors)\n                \ntmp_new = cbind.data.frame(tmp, tmp_factors)\n                \n                \n#tmp_imp$VAR_0543 <- NULL; tmp_imp$VAR_0704 <- NULL; tmp_imp$VAR_0920 <- NULL\n                \n#tmp_imp$VAR_1087 <- NULL; tmp_imp$VAR_0891 <- NULL; tmp_imp$VAR_0908 <- NULL\n                \n#tmp_imp$VAR_0887 <- NULL; tmp_imp$VAR_0298 <- NULL; tmp_imp$VAR_0318 <- NULL\n                \n#tmp_imp$VAR_1494 <- NULL; tmp_imp$VAR_0608 <- NULL; tmp_imp$VAR_0330 <- NULL\n                \n#tmp_imp$VAR_1247 <- NULL; tmp_imp$VAR_0073 <- NULL; tmp_imp$VAR_0241 <- NULL\n                \n############################################################################################\n                \nrm(nzv); rm(test_imp); rm(tmp); rm(tmp_date); rm(tmp_pre_pred)\n                \nrm(train); rm(datecolumns);\n\nrm(names); rm(tmp_Imp); rm(tmp_factors); rm(imp_feature); rm(nms_df);rm(nms)\n                \n######################################################################################\n                \nrm(tmp); rm(tmp_date); rm(tmp_imp); rm(tmp_imp_2); rm(tmp_imp_2d); rm(sum1)\nrm(tmp1); rm(tmp_count); rm(tmp_pre)\n\ngc()                \n                \ntmp_new[is.na(tmp_new)] <- -9999999\n                \n                \nfeature.names <- names(tmp_new)\n                \nfor (f in feature.names) {\n\nif (class(tmp_new[[f]]) == \"character\") {\n\nlevels <- unique((tmp_new[[f]]))\n                    \ntmp_new[[f]] <-as.integer(factor(tmp_new[[f]], levels = levels))\n                    \n}\n                  \n}\n                \n                \n##############################################################################\n                \ntrain <- tmp_new[c(1:145231),]\n                \ntest <- tmp_new[c(145232:290463),]\n                \ndim(train); dim(test)\n                \ngc()\n                \n                \nsplit <- createDataPartition(train_target, p = .9, list = FALSE)\n                \nresponse <- train_target\n                \ntraining <- train[split,]\n                \ntesting  <- train[-split,]\n                \nresponse_testing <- response[-split]\n                \nresponse_training <- response[split]\n\nfeature.names <- names(train)\n\ndtrain <- xgb.DMatrix(data.matrix(training[,feature.names]), label = response_training)\n                \ndval <- xgb.DMatrix(data.matrix(testing[,feature.names]), label = response_testing)\n                \nwatchlist <- list(train = dtrain, test = dval)\n\nparam <- list(  objective           = \"binary:logistic\", \n                \n                # booster = \"gblinear\",\n                \n                eta                 = 0.014, \n                \n                max_depth           = 10,  \n                \n                subsample           = 0.7,\n                \n                colsample_bytree    = 0.7,\n                \n                eval_metric         = \"auc\",\n                \n                nthreads = -1\n                \n)                \ncl <- makeCluster(2); registerDoParallel(cl)                \n                \nclf_first <- xgb.train( params = param,\n                    \n                        data = dtrain,\n                    \n                        nrounds = 1000,\n                    \n                        verbose = 2,\n                    \n                        watchlist = watchlist,\n                    \n                        \n                    \n                        maximize = TRUE\n                  )\n\nxgb.save(model = clf_first, \"1012015xgb\")\n\nsubmission <- data.frame(ID = test_ID)\n                \nsubmission$target <- NA\n                \nsubmission[,\"target\"] <- predict(clf_first, \n                                 \n                                 data.matrix(test[,feature.names]))\n                \nwrite_csv(submission, \"10122015.csv\")\n                \n#############################################################################\n#If restarted\n                \nxgb.load(\"10072015xgb\")\n                \nptrain = predict(clf_first, dtrain, outputmargin = T)\n                \nsetinfo(dtrain, \"base_margin\", ptrain)\n                \n                \nclf_first_1 <- xgboost( params = param,\n                        \n                        data = dtrain,\n                    \n                        nrounds = 1000,\n                    \n                        verbose = 2,\n                    \n                        nthread = 2,\n                    \n                        maximize = TRUE\n                  )\n                \nsubmission <- data.frame(ID = test_ID)\n                \nsubmission$target <- NA\n                \nsubmission[,\"target\"] <- predict(clf_first_1, data.matrix(test[,feature.names]))\n                \nwrite_csv(submission, \"10082015.csv\")\n                ",
    "created" : 1446920780567.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3818150753",
    "id" : "74494AFF",
    "lastKnownWriteTime" : 1444848749,
    "path" : "D:/kaggle/Springleaf/new_pp_run.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "type" : "r_source"
}