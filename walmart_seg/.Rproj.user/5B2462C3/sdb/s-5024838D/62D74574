{
    "contents" : "# implement log loss function and test it with test case from here: \n\n# http://www.kaggle.com/c/emc-data-science/forums/t/2149/is-anyone-noticing-difference-betwen-validation-and-leaderboard-error\n\n# note: the function only takes in matrices\n\ncheckLogLoss <- function(model, data) {\n  \n  # LogLoss Function\n  \n  LogLoss <- function(actual, predicted, eps = 1e-15) {\n    \n    predicted <- pmax(pmin(predicted, 1 - eps), eps)\n    \n    -sum(actual*log(predicted))/nrow(actual)\n  }\n  \n  # create dummy predictions and compare with fitted model\n  \n  pred <- as.matrix(predict(model, newdata = data, type = 'prob'))\n  \n  #check which works -- top or bottom\n  \n  #pred <- predict(clf, data.matrix(data[, feature.names])) \n  \n  dummy.fit <- dummyVars(~ TripType, data = data, levelsOnly = T)  \n  \n  truth <- predict(dummy.fit, newdata = data)  # predict ground truth using validation set\n  \n  LogLoss(truth, pred)\n}\n\n#############################################################################################################\n\n# function to create submissions\n\n#requires creation of visit_num in init file\n\nsubmit <- function(model, data, file) {\n  \n  # create predictions and write out to csv.file\n  \n  pred <- predict(clf, data.matrix(data[, feature.names])) \n  \n  pred <- matrix(pred, nrow=38, ncol=length(pred)/38) #there are total 38 classes \n  \n  pred = data.frame(t(pred))\n  \n  sample <- read_csv('sample_submission.csv') \n  \n  cnames <- names(sample)[2:ncol(sample)] \n  \n  names(pred) <- cnames\n  \n  submission <- cbind.data.frame(VisitNumber = visit_num , pred) \n  \n  submission <- setDT(submission)\n  \n  submission <- (submission[ , lapply(.SD, mean), by = VisitNumber])\n  \n  #write_csv(submission, \"D:/kaggle/walmart_seg/submission/file.csv\")\n  \n  write_csv(submission,  file)\n}\n\n############################################################################################################\n\n#function for grid search\n\n# grid search\n\nfor (depth in c(9, 10, 8)) {\n  \n  for (rounds in c(2000, 3000)) {\n    \n    for(eta in c(0.3, 0.2, 0.1)){\n      \n      # train\n      param <- list(objective = \"multi:softprob\",\n                    \n                    eval_metric = \"mlogloss\",\n                    \n                    num_class = numberOfClasses,\n                    \n                    max_depth = depth ,\n                    \n                    eta = eta,\n                    \n                    nthreads = 4\n      )\n      \n      \n      clf <- xgb.train(params = param, data = dtrain, watchlist = watchlist, nrounds = rounds,\n                       \n                       verbose = 1, maximize = T)\n      gc()\n      \n      \n      xgb.save(clf, paste0(\"clf\", \"_\", rounds, \"_\",depth, \"_\", eta) )\n      \n      #scoring to be done -- issues with function scoring\n      \n    }     \n  }\n}  \n\n\n\n##########################################################################################\n#using owen`s Amazon code approach\n\nmy.f2cnt <- function(th2, vn1, vn2, filter=TRUE) {\n  \n  df <- data.frame(f1=th2[,vn1], f2=th2[,vn2], filter=filter)\n  \n  sum1 <- sqldf(\"select f1, f2, count(*) as cnt \n                \n                from df \n                \n                where filter=1 \n                \n                group by 1,2\")\n  \n  tmp <- sqldf(\"select b.cnt \n               \n               from df a left join sum1 b \n               \n               on a.f1=b.f1 and a.f2=b.f2\")\n  \n  tmp$cnt[is.na(tmp$cnt)] <- 0\n  \n  return(tmp$cnt)\n  \n}\n\n#3 way count\n\nmy.f3cnt<-function(th2, vn1, vn2, vn3, filter=TRUE) {\n  \n  df<-data.frame(f1=th2[,vn1], f2=th2[,vn2], f3=th2[, vn3], filter=filter)\n  \n  sum1<-sqldf(\"select f1, f2, f3, count(*) as cnt \n              \n              from df \n              \n              where filter=1 \n              \n              group by 1,2, 3\")\n  \n  tmp<-sqldf(\"select b.cnt \n             \n             from df a left join sum1 b \n             \n             on a.f1=b.f1 and a.f2=b.f2 and a.f3=b.f3\")\n  \n  tmp$cnt[is.na(tmp$cnt)]<-0\n  \n  return(tmp$cnt)\n  \n}\n\n\n#############################################################################################################\n\naddAggFeatures <- function(data) {\n  \n  \n  # add new features\n  \n  mutate(data, feat_sum = as.integer(rowSums(data[, 1:ncol(tmp_new)])),  # count sum of features by row\n         \n         feat_var = as.integer(apply(data[, 1:ncol(tmp_new)], 1, var)),  # variance of features by row\n         \n         feat_filled = as.integer(rowSums(data[, 1:ncol(tmp_new)] != 0))  # count no. of non-empty features\n  )\n  \n}\n\n################################################################################################################\n\n# should write a function for grid search\n\n# should write a function for random search\n\n# random search code found in h2o.ai gbm otto code is a good start ; link below\n\n# https://github.com/harell/Kaggle-Otto-Group-Product-Classification-Challenge/blob/master/models/gbm%20type%201.R\n\n\n# below function is a random search code found in forums\n\n#https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/12947/achieve-0-50776-on-the-leaderboard-in-a-minute-with-xgboost/69427#post69427\n\nrandom_search <- function(n_set, threads){\n  \n  #param is a list of parameters\n  \n  # Set necessary parameter\n  \n  param <- list(\"objective\" = \"multi:softprob\",\n                \n                \"max_depth\"=6,\n                \n                \"eta\"=0.1,\n                \n                \"subsample\"=0.7,\n                \n                \"colsample_bytree\"= 1,\n                \n                \"gamma\"=2,\n                \n                \"min_child_weight\"=4,\n                \n                \"eval_metric\" = \"mlogloss\",\n                \n                \"silent\"=1,\n                \n                \"num_class\" = 9,\n                \n                \"nthread\" = threads)\n  \n  param_list <- list()\n  \n  for (i in seq(n_set)){\n    \n    ## n_par <- length(param)\n    \n    \n    param$max_depth <- sample(3:7,1, replace=T)\n    \n    param$eta <- runif(1,0.01,0.6)\n    \n    param$subsample <- runif(1,0.1,1)\n    \n    param$colsample_bytree <- runif(1,0.1,1)\n    \n    param$min_child_weight <- sample(1:17,1, replace=T)\n    \n    \n    param$gamma <- runif(1,0.1,10)\n    \n    param$min_child_weight <- sample(1:15,1, replace=T)\n    \n    param_list[[i]] <- param\n    \n  }\n  \n  return(param_list)\n  \n}",
    "created" : 1446838547373.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3141643912",
    "id" : "62D74574",
    "lastKnownWriteTime" : 1447425084,
    "path" : "D:/kaggle/walmart_seg/UTILIS.R",
    "project_path" : "UTILIS.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}