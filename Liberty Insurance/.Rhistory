"subsample" = .7,
"colsample_bytree" = .8,
"scale_pos_weight" = 1.5
)
############################################################################################################
train.data[,predictor]
x <- train.data[,predictor]
y <- train.data[,labelName]
caret_xgb <- train(x,  y,
method = "xgbTree" , trControl = control,
metric = "Gini" ,
tuneGrid = grid_xgb,
savePredictions=TRUE,
"min_child_weight" = 20,
"subsample" = .7,
"colsample_bytree" = .8,
"scale_pos_weight" = 1.5
)
train <- read_csv("~/Kaggle/Liberty Insurance/DATA/CSV/train.csv")
test <- read_csv("~/Kaggle/Liberty Insurance/DATA/CSV/test.csv")
train_Id <- train$Id
test_Id <- test$Id
# response variable from training data
train_y <- train$Hazard
# predictor variables from training
train_x <- subset(train, select = -c(Id, Hazard))
train_x <- sparse.model.matrix(~., data = train_x)
# predictor variables from test
test_x <- subset(test, select = -c(Id))
test_x <- sparse.model.matrix(~., data = test_x)
grid <- expand.grid(eta = 0.035,
max_depth = 5,
nrounds = 400)
trainControlxgbTree <- trainControl(method = "repeatedcv", number = 5,
repeats = 3, summaryFunction = NormalizedGini ,
verboseIter = T
)
xgbTree_caret_max <- train(x = train_x,
y = train_y,
method = "xgbTree" ,
trControl = trainControlxgbTree,
metric = "Gini" ,
tuneGrid = grid,
savePredictions=TRUE,
"min_child_weight" = 20,
"subsample" = .7,
"colsample_bytree" = .8,
"scale_pos_weight" = 1.5
)
train <- read_csv("~/Kaggle/Liberty Insurance/DATA/CSV/train.csv")
test <- read_csv("~/Kaggle/Liberty Insurance/DATA/CSV/test.csv")
train_x <- subset(train, select = -c(Hazard))
train_x <- subset(train, select = -c(Hazard))
train_x <- sparse.model.matrix(~., data = train_x)
train_y <- train$Hazard
train_x$Hazard <- train_y
split <- floor(nrow(train_x)/3)
##########################################################################################################
train.data <- train_x[0:split, ]
validation.data <- train_x[(split+1):(split*2), ]
test.data <- train_x[(split*2+1):nrow(train_x),]
train <- read_csv("~/Kaggle/Liberty Insurance/DATA/CSV/train.csv")
test <- read_csv("~/Kaggle/Liberty Insurance/DATA/CSV/test.csv")
train_x <- subset(train, select = -c(Id,Hazard))
train_x <- sparse.model.matrix(~., data = train_x)
train_y <- train$Hazard
split <- floor(nrow(train_x)/3)
##########################################################################################################
train.data <- train_x[0:split, ]
validation.data <- train_x[(split+1):(split*2), ]
test.data <- train_x[(split*2+1):nrow(train_x),]
###########################################################################################################
train.Hazard <- train_y[0:split, ]
split
dim(train_y)
dim(train$Hazard)
train.Hazard <- train_y[0:split]
validation.Hazard <- train_y[(split+1):(split*2)]
test.Hazard <- train_y[(split*2+1):nrow(train_y)]
control <- trainControl(method = "repeatedcv", number = 10, repeats = 1, verboseIter = T,
summaryFunction = NormalizedGini
)
grid_xgb <- expand.grid(eta = 0.035,
max_depth = 5,
nrounds = 400)
caret_xgb <- train(train.data, train.Hazard,
method = "xgbTree" , trControl = control,
metric = "Gini" ,
tuneGrid = grid_xgb,
savePredictions=TRUE,
"min_child_weight" = 20,
"subsample" = .7,
"colsample_bytree" = .8,
"scale_pos_weight" = 1.5
)
grid_xgb <- expand.grid(eta = 0.05,
max_depth = 5,
nrounds = 400)
caret_xgb <- train(train.data, train.Hazard,
method = "xgbTree" , trControl = control,
metric = "Gini" ,
tuneGrid = grid_xgb,
savePredictions=TRUE,
"min_child_weight" = 20,
"subsample" = .7,
"colsample_bytree" = .8,
"scale_pos_weight" = 1.6
)
grid_xgb <- expand.grid(eta = 0.035,
max_depth = 5,
nrounds = 400)
caret_xgb <- train(train.data, train.Hazard,
method = "xgbTree" , trControl = control,
metric = "Gini" ,
tuneGrid = grid_xgb,
savePredictions=TRUE,
"min_child_weight" = 20,
"subsample" = .7,
"colsample_bytree" = .8,
"scale_pos_weight" = 1.5
)
grid_xgb_1 <- expand.grid(eta = 0.05,
max_depth = 5,
nrounds = 400)
caret_xgb_1 <- train(train.data, train.Hazard,
method = "xgbTree" , trControl = control,
metric = "Gini" ,
tuneGrid = grid_xgb_1,
savePredictions=TRUE,
"min_child_weight" = 20,
"subsample" = .7,
"colsample_bytree" = .8,
"scale_pos_weight" = 1.6
)
#############################################################################################################
grid_xgb_2 <- expand.grid(eta = 0.04,
max_depth = 5,
nrounds = 400)
caret_xgb_2 <- train(train.data, train.Hazard,
method = "xgbTree" , trControl = control,
metric = "Gini" ,
tuneGrid = grid_xgb_2,
savePredictions=TRUE,
"min_child_weight" = 20,
"subsample" = .8,
"colsample_bytree" = .8,
"scale_pos_weight" = 1.7
)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3, verboseIter = T,
summaryFunction = NormalizedGini
)
grid_xgb <- expand.grid(eta = 0.035,
max_depth = 5,
nrounds = 400)
caret_xgb <- train(train.data, train.Hazard,
method = "xgbTree" , trControl = control,
metric = "Gini" ,
tuneGrid = grid_xgb,
savePredictions=TRUE,
"min_child_weight" = 20,
"subsample" = .7,
"colsample_bytree" = .8,
"scale_pos_weight" = 1.5
)
###########################################################################################################
grid_xgb_1 <- expand.grid(eta = 0.05,
max_depth = 5,
nrounds = 400)
caret_xgb_1 <- train(train.data, train.Hazard,
method = "xgbTree" , trControl = control,
metric = "Gini" ,
tuneGrid = grid_xgb_1,
savePredictions=TRUE,
"min_child_weight" = 20,
"subsample" = .7,
"colsample_bytree" = .8,
"scale_pos_weight" = 1.6
)
#############################################################################################################
grid_xgb_2 <- expand.grid(eta = 0.04,
max_depth = 5,
nrounds = 400)
caret_xgb_2 <- train(train.data, train.Hazard,
method = "xgbTree" , trControl = control,
metric = "Gini" ,
tuneGrid = grid_xgb_2,
savePredictions=TRUE,
"min_child_weight" = 20,
"subsample" = .8,
"colsample_bytree" = .8,
"scale_pos_weight" = 1.7
)
validation.data$xgb_1 <- predict(caret_xgb, validation.data)
validation.data$xgb_2 <- predict(caret_xgb_1, validation.data)
validation.data$xgb_3 <- predict(caret_xgb_2, validation.data)
test.data$xgb_1 <- predict(caret_xgb, test.data)
test.data$xgb_2 <- predict(caret_xgb_1, test.data)
test.data$xgb_3 <- predict(caret_xgb_2, test.data)
validation.data$xgb_1 <- predict(caret_xgb, validation.data)
validation.data$xgb_2 <- predict(caret_xgb_1, validation.data)
validation.data$xgb_3 <- predict(caret_xgb_2, validation.data)
test.data$xgb_1 <- predict(caret_xgb, test.data)
test.data$xgb_2 <- predict(caret_xgb_1, test.data)
test.data$xgb_3 <- predict(caret_xgb_2, test.data)
validation.data$xgb_1 <- predict(caret_xgb, validation.data)
xgb_1 <- predict(caret_xgb, validation.data)
control_1 <- trainControl(method = "repeatedcv", number = 10, repeats = 5, verboseIter = T,
summaryFunction = NormalizedGini
)
final_blender_model <- train(validation.data, validation.Hazard, method="xgbTree", trControl=control_1,
tuneGrid = grid_xgb,savePredictions=TRUE,
"min_child_weight" = 20, "subsample" = .7,
"colsample_bytree" = .8, "scale_pos_weight" = 1.5
)
xgb_1 <- predict(caret_xgb, validation.data)
xgb_2 <- predict(caret_xgb_1, validation.data)
xgb_3 <- predict(caret_xgb_2, validation.data)
txgb_1 <- predict(caret_xgb, test.data)
txgb_2 <- predict(caret_xgb_1, test.data)
txgb_3 <- predict(caret_xgb_2, test.data)
head(validation.data)
names(validation.data)
cclass(validation.data)
class(validation.data)
pred <- predict(final_blender_model, test.data)
beep("fanfare")
sub <- data.frame("Id" = test.data$Id, "Hazard" = pred)
length(pred)
split <- floor(nrow(train)/3)
Id = train$Id[(split*2+1):nrow(train)]
length(Id)
sub <- data.frame("Id" = Id, "Hazard" = pred)
write.csv(sub, "blend_s.csv", row.names = FALSE)
test <- read_csv("~/Kaggle/Liberty Insurance/DATA/CSV/test.csv")
test_x <- subset(test, select = -c(Id))
test_x <- sparse.model.matrix(~., data = test_x)
test_Id <- test$Id
preds <- predict(final_blender_model, test)
preds <- predict(final_blender_model, test_x)
subs <- data.frame("Id" = test_Id, "Hazard" = preds)
length(preds)
write.csv(subs, "blend.csv", row.names = FALSE)
sessionInfo()
library("RevoUtilsMath", lib.loc="C:/Program Files/RRO/R-3.2.1/library")
sessionInfo()
require(Matrix)
require(readr)
require(caret)
train <- read_csv("~/Kaggle/Liberty Insurance/DATA/CSV/train.csv")
test <- read_csv("~/Kaggle/Liberty Insurance/DATA/CSV/test.csv")
train[sapply(train, is.character)] <- lapply(sapply(train, is.character), as.factor)
test[sapply(test, is.character)] <- lapply(sapply(test, is.character), as.factor)
#seperate train into train.data & validation.data
split <- floor(nrow(train)/3)
##########################################################################################################
train.data <- train[0:split, ]
validation.data <- train[(split+1):(split*2), ]
test.data <- train[(split*2+1):nrow(train),]
###########################################################################################################
labelName <- 'Hazard'
predictor <- names(train.data)[names(train.data) != labelName]
control <- trainControl(method = "repeatedcv", number = 10, repeats = 1, verboseIter = T,
summaryFunction = NormalizedGini
)
###########################################################################################################
#BECHMARK MODEL
gbm_grid <- expand.grid(interaction.depth =  20,
n.trees = 200,
shrinkage =  0.05,
n.minobsinnode = 200
)
benchmark <- train(validation.data[,predictor], validation.data[,labelName],
method = 'gbm', trControl = control,  metric = "Gini", tuneGrid = gbm_grid
)
system.time()
sessionInfo()
require(xgboost)
# load in the agaricus dataset
data(agaricus.train, package='xgboost')
data(agaricus.test, package='xgboost')
dtrain <- xgb.DMatrix(agaricus.train$data, label = agaricus.train$label)
dtest <- xgb.DMatrix(agaricus.test$data, label = agaricus.test$label)
nround <- 2
param <- list(max.depth=2,eta=1,silent=1,nthread = 2, objective='binary:logistic')
cat('running cross validation\n')
# do cross validation, this will print result out as
# [iteration]  metric_name:mean_value+std_value
# std_value is standard deviation of the metric
xgb.cv(param, dtrain, nround, nfold=5, metrics={'error'})
predict(xgb.cv, dtest)
xgb.cv(param, dtrain, nround, nfold=5, metrics={'error'}, prediction = T)
require(xgboost)
# load in the agaricus dataset
data(agaricus.train, package='xgboost')
data(agaricus.test, package='xgboost')
dtrain <- xgb.DMatrix(agaricus.train$data, label = agaricus.train$label)
dtest <- xgb.DMatrix(agaricus.test$data, label = agaricus.test$label)
watchlist <- list(eval = dtest, train = dtrain)
###
# advanced: start from a initial base prediction
#
print('start running example to start from a initial prediction')
# train xgboost for 1 round
param <- list(max.depth=2,eta=1,nthread = 2, silent=1,objective='binary:logistic')
bst <- xgb.train( param, dtrain, 1, watchlist )
bst <- xgb.train( param, dtrain, 1, watchlist )
require(xgboost)
# load in the agaricus dataset
data(agaricus.train, package='xgboost')
data(agaricus.test, package='xgboost')
dtrain <- xgb.DMatrix(agaricus.train$data, label = agaricus.train$label)
dtest <- xgb.DMatrix(agaricus.test$data, label = agaricus.test$label)
nround <- 2
param <- list(max.depth=2,eta=1,silent=1,nthread = 2, objective='binary:logistic')
cat('running cross validation\n')
# do cross validation, this will print result out as
# [iteration]  metric_name:mean_value+std_value
# std_value is standard deviation of the metric
xgb.cv(param, dtrain, nround, nfold=5, metrics={'error'}, prediction = T)
res <- xgb.cv(param, dtrain, nround, nfold=5, metrics={'error'}, prediction = T)
dim(dtrain)
dim(agaricus.train)
dim(agaricus.train$data)
library('caret')
library('mlbench')
library('pROC')
data(Sonar)
set.seed(107)
inTrain <- createDataPartition(y = Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTrain,]
testing <- Sonar[-inTrain,]
my_control <- trainControl(
method='boot',
number=25,
savePredictions=TRUE,
classProbs=TRUE,
index=createResample(training$Class, 25),
summaryFunction=twoClassSummary
)
library('rpart')
library('caretEnsemble')
install.packages('caretEnsemble')
library('caretEnsemble')
model_list <- caretList(
Class~., data=training,
trControl=my_control,
methodList=c('glm', "xgbTree")
)
warning(model_list)
print(p)
p <- as.data.frame(predict(model_list, newdata=head(testing)))
print(p)
library('mlbench')
library('randomForest')
library('nnet')
model_list_big <- caretList(
Class~., data=training,
trControl=my_control,
metric='ROC',
methodList=c('glm', 'xgbTree'),
tuneList=list(
rf1=caretModelSpec(method='gbm'),
rf2=caretModelSpec(method='gbm', preProcess='pca'),
nn=caretModelSpec(method='nnet', tuneLength=2, trace=FALSE)
)
)
greedy_ensemble <- caretEnsemble(model_list)
summary(greedy_ensemble)
model_preds <- lapply(model_list, predict, newdata=testing, type='prob')
model_preds <- lapply(model_preds, function(x) x[,'M'])
model_preds <- data.frame(model_preds)
ens_preds <- predict(greedy_ensemble, newdata=testing)
model_preds$ensemble <- ens_preds
colAUC(model_preds, testing$Class)
library('caTools')
colAUC(model_preds, testing$Class)
glm_ensemble <- caretStack(
model_list,
method='xgbTree',
metric='ROC',
trControl=trainControl(
method='boot',
number=10,
savePredictions=TRUE,
classProbs=TRUE,
summaryFunction=twoClassSummary
)
)
model_preds2 <- model_preds
model_preds2$ensemble <- predict(glm_ensemble, newdata=testing, type='prob')$M
CF <- coef(glm_ensemble$ens_model$finalModel)[-1]
colAUC(model_preds2, testing$Class)
library('xgboost')
library('xgboost')
xgb_ensemble <- caretStack(
model_list,
method='xgbTree',
verbose=FALSE,
tuneLength=10,
metric='ROC',
trControl=trainControl(
method='boot',
number=10,
savePredictions=TRUE,
classProbs=TRUE,
summaryFunction=twoClassSummary
)
)
model_preds3 <- model_preds
model_preds3$ensemble <- predict(xgb_ensemble, newdata=testing, type='prob')$M
colAUC(model_preds3, testing$Class)
rm(list = ls())
require(readr)
require(Matrix)
require(caret)
require(caretEnsemble)
train <- read_csv("~/Kaggle/Liberty Insurance/DATA/CSV/train.csv")
test <- read_csv("~/Kaggle/Liberty Insurance/DATA/CSV/test.csv")
train <- read_csv("D:/Kaggle/Liberty Insurance/DATA/CSV/train.csv")
test <- read_csv("D:/Kaggle/Liberty Insurance/DATA/CSV/test.csv")
train <- read_csv("D:/Kaggle/Liberty Insurance/DATA/CSV/train.csv")
test <- read_csv("D:/Kaggle/Liberty Insurance/DATA/CSV/test.csv")
factorToNumeric <- function(train, test, response, variables, metrics){
library(qdapTools)
temp <- data.frame(c(rep(0,nrow(test))), row.names = NULL)
for (variable in variables){
for (metric in metrics) {
x <- tapply(train[, response], train[,variable], metric)
x <- data.frame(row.names(x),x, row.names = NULL)
temp <- data.frame(temp,round(lookup(test[,variable], x),2))
colnames(temp)[ncol(temp)] <- paste(metric,variable, sep = "_")
}
}
return (temp[,-1])
}
str(train)
str(test)
factorToNumeric(train, train, "Hazard", "T1_V4", c("mean","median","sd"))
str(train$T1_V4)
head(
factorToNumeric(train, train, "Hazard", "T1_V4", c("mean","median","sd")))
str(train)
table(train$T2_V15)
head(factorToNumeric(train, train, "Hazard", "T2_V15", c("mean","median","sd")))
table(train$T2_V15)
class(train$T2_V15) <- as.factor((train$T2_V15))
class(train$T2_V15)
table(train$T2_V15)
response =  "Hazard"; variable =  "T2_V15"; metric = "mean"
x <- tapply(train[, response], train[,variable], metric)
table(x)
table(train[, response])
table(train[, variable])
metric = "mean"
tapply(train[, response], train[,variable], metric)
x <- tapply(train[, response], train[,variable], metric)
x
x <- data.frame(row.names(x),x, row.names = NULL)
x
str(x)
test = train
temp <- data.frame(c(rep(0,nrow(test))), row.names = NULL)
temp <- data.frame(temp,round(lookup(test[,variable], x),2))
response =  "Hazard"; variable =  "T1_V4"; metric = "mean"
x <- tapply(train[, response], train[,variable], metric)
x
str(x)
x <- data.frame(row.names(x),x, row.names = NULL)
str(x)
temp <- data.frame(temp,round(lookup(test[,variable], x),2))
temp
head(temp)
colnames(temp)[ncol(temp)] <- paste(metric,variable, sep = "_")
head(temp)
return (temp[,-1])
head(temp[,-1])
head(temp[,-1], 25)
str(train)
str(train)
rm(list = ls())
train <- read_csv("D:/Kaggle/Liberty Insurance/DATA/CSV/train.csv")
test <- read_csv("D:/Kaggle/Liberty Insurance/DATA/CSV/test.csv")
factorToNumeric <- function(train, test, response, variables, metrics){
library(qdapTools)
temp <- data.frame(c(rep(0,nrow(test))), row.names = NULL)
for (variable in variables){
for (metric in metrics) {
x <- tapply(train[, response], train[,variable], metric)
x <- data.frame(row.names(x),x, row.names = NULL)
temp <- data.frame(temp,round(lookup(test[,variable], x),2))
colnames(temp)[ncol(temp)] <- paste(metric,variable, sep = "_")
}
}
return (temp[,-1])
}
str(train)
for (f in names(train)) {
if (class(train[[f]]) == "character") {
levels <- unique(c(train[[f]]))
train[[f]] <- as.integer(factor(train[[f]], levels=levels))
}
}
len = length(train)
for (i in 1:len) {
print(paste0( i / (len) *100, "%"))
levels <- unique(train[[i]])
train[ , i] <- factor(train[ , i], levels = levels)
}
str(train)
head(factorToNumeric(train, train, "Hazard", "T1_V4", c("mean","median","sd")))
head(factorToNumeric(train, train, "Hazard", "T1_V4", c("mean")))
rm(list = ls())
