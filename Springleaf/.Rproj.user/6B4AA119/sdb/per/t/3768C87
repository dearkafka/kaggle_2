{
    "contents" : "\nlibrary(readr)\n\nlibrary(xgboost)\n\n#escape file path to read data into file (memory)\n\ntrain <- read_csv(\"DATA/CSV/train.csv\")\n\ntest <- read_csv(\"DATA/CSV/test.csv\")\n\nnames(train); class(train); str(train)\n\nsapply(train, class)\n\n\ncat(\"reading the train and test data\\n\")\n\nfeature.names <- names(train)[2:ncol(train)-1]\n\nfor (f in feature.names) {\n  \n  if (class(train[[f]])==\"character\") {\n    \n    levels <- unique(c(train[[f]], test[[f]]))\n    \n    train[[f]] <- as.integer(factor(train[[f]], levels=levels))\n    \n    test[[f]]  <- as.integer(factor(test[[f]],  levels=levels))\n  }\n}\n\ncat(\"replacing missing values with -1\\n\")\n\ntrain[is.na(train)] <- -1\n\ntest[is.na(test)]   <- -1\n\n# cat(\"training a XGBoost classifier\\n\")\n# clf <- xgboost(data        = data.matrix(train[,feature.names]),\n#               label       = train$target,\n#               nrounds     = 100, # 100 is better than 200\n#               objective   = \"binary:logistic\",\n#               eval_metric = \"auc\")\n\n\ncat(\"sampling train to get around 8GB memory limitations\\n\")\ntrain <- train[sample(nrow(train), 80000),]\nh <- sample(nrow(train), 40000)\ntrain <-train[h,]\ngc()\n\ncat(\"Making train and validation matrices\\n\")\n\ndtrain <- xgb.DMatrix(data.matrix(train[,feature.names]), label=train$target)\n\nval<-train[-h,]\ngc()\n\ndval <- xgb.DMatrix(data.matrix(val[,feature.names]), label=val$target)\n\nwatchlist <- watchlist <- list(eval = dval, train = dtrain)\n\nparam <- list(  objective           = \"binary:logistic\", \n                # booster = \"gblinear\",\n                eta                 = 0.001,\n                max_depth           = 13,  # changed from default of 6\n                subsample           = 0.6,\n                colsample_bytree    = 0.75,\n                eval_metric         = \"auc\"\n                # alpha = 0.0001, \n                # lambda = 1\n)\n\nclf <- xgb.train(   params              = param, \n                    data                = dtrain, \n                    nrounds             = 50, # changed from 300\n                    verbose             = 2, \n                    early.stop.round    = 10,\n                    watchlist           = watchlist,\n                    maximize            = TRUE)\n\ncat(\"making predictions in batches due to 8GB memory limitation\\n\")\n\nsubmission <- data.frame(ID=test$ID)\nsubmission$target <- NA \nfor (rows in split(1:nrow(test), ceiling((1:nrow(test))/10000))) {\nsubmission[rows, \"target\"] <- predict(clf, data.matrix(test[rows,feature.names]))\n}  \n\ncat(\"saving the submission file\\n\")\nwrite_csv(submission, \"xgb_b6.csv\")",
    "created" : 1440323279725.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1567869397",
    "id" : "3768C87",
    "lastKnownWriteTime" : 1440560483,
    "path" : "~/Kaggle/Springleaf/READ_DATA.R",
    "project_path" : "READ_DATA.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}